{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page(pesquisa,page=1):\n",
    "    p = pesquisa.split()\n",
    "    p1 = '-'.join(p)\n",
    "    p2 = '%20'.join(p)\n",
    "    \n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.72 Safari/537.36'}\n",
    "    url = f'https://www.catho.com.br/vagas/{p1}/?q={p2}&page={page}'\n",
    "    session = requests.get(url,headers)\n",
    "    soup = BeautifulSoup(session.content,'html.parser')\n",
    "  \n",
    "    \n",
    "    return soup\n",
    "\n",
    "def transform_page(soup):\n",
    "    data = {'title':[],'descrição':[],'local':[],'salario':[],'link':[]}\n",
    "    \n",
    "    articles = soup.find_all('article')\n",
    "    for art in articles[3::]:\n",
    "        try:    data['title'].append(art.h2.text)\n",
    "        except: data['title'].append('')\n",
    "            \n",
    "        try:    data['descrição'].append(art.find('span',{'class':\"job-description\"}).text)\n",
    "        except: data['descrição'].append('')\n",
    "            \n",
    "        try:    data['local'].append(art.find('button',{'class':\"sc-jhAzac fBEAcd\"}).text)\n",
    "        except: data['local'].append('')\n",
    "            \n",
    "        try:    data['salario'].append(str(art.find('div',{'class':\"sc-eqIVtm bTmKXM\"}).text.replace('R$','')))\n",
    "        except: data['salario'].append('')\n",
    "            \n",
    "        try:    data['link'].append(art.a.attrs['href'])\n",
    "        except: data['link'].append('')\n",
    "            \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def get_descrição_completa(links):\n",
    "    \n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.72 Safari/537.36'}\n",
    "    desc_completa = []\n",
    "    \n",
    "    for link in links:\n",
    "        session = requests.get(link,headers)\n",
    "        soup = BeautifulSoup(session.content,'html.parser')\n",
    "        \n",
    "        try:    \n",
    "            desc_string = soup.find('section',{'class':'descricaoVaga'}).p.text\n",
    "            desc_completa.append(desc_string.replace('\\n','').replace('  ',''))\n",
    "                \n",
    "        except: \n",
    "            desc_completa.append('')\n",
    "\n",
    "    return  desc_completa  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "areas = ['Analista de controladoria senior', 'Analista de planejamento financeiro']\n",
    "\n",
    "\n",
    "\n",
    "soup = extract_page(areas[0])\n",
    "df_all = transform_page(soup)\n",
    "    \n",
    "for i in range(1,40):\n",
    "    soup = extract_page(areas[0],i)\n",
    "    df = transform_page(soup)\n",
    "    df_all = pd.concat([df_all,df],ignore_index=True)\n",
    "\n",
    "for area in areas[1:]:\n",
    "    for i in range(1,40):\n",
    "        soup = extract_page(area,i)\n",
    "        df = transform_page(soup)\n",
    "        df_all = pd.concat([df_all,df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_excel('Catho Analistas controladoria.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = df_all['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_description = get_descrição_completa(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['descrição completa'] = all_description\n",
    "df_all = df_all.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_excel('Catho Analistas controladoria.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
