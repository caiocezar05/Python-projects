{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# importing libraries to plot the wordcloud\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local = \"São Paulo\"\n",
    "email = 'caiocezar05@gmail.com'\n",
    "senha = 'psx36547'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(email,senha):\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\a92550\\Downloads\\chromedriver.exe\")\n",
    "    driver.get('https://www.linkedin.com/login')\n",
    "    # waiting load\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Search for login and password inputs, send credentions\n",
    "    driver.find_element_by_id('username').send_keys(email)\n",
    "    driver.find_element_by_id('password').send_keys(senha)\n",
    "    try:\n",
    "        driver.find_element_by_XPATH('/html/body/div/div[1]/section/div[2]/div/article/footer/div/div/button[1]').click()\n",
    "    except: pass\n",
    "\n",
    "    driver.find_element_by_id('password').send_keys(Keys.RETURN)\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def job_Search_complete(driver,cargo,local,npages):\n",
    "    \n",
    "    driver.get(\n",
    "    f\"https://www.linkedin.com/jobs/search/?currentJobId=2662929045&geoId=106057199&keywords={cargo}&location={local}\")\n",
    "    # waiting load\n",
    "    time.sleep(5)\n",
    "\n",
    "    data = {'job':[],'description':[]}\n",
    "\n",
    "    # each page show us some jobs, sometimes show 25, others 13 or 21 ¯\\_(ツ)_/¯\n",
    "    # with this knowledge I created a loop that will check how many jobs the page is listing\n",
    "    # linkedin show us 40 jobs pages, then the line below will repeat 40 times\n",
    "    for i in range(2, npages+1):\n",
    "        try:\n",
    "        # each page show us some jobs, sometimes show 25, others 13 or 21 ¯\\_(ツ)_/¯\n",
    "            jobs_lists = driver.find_element_by_class_name('jobs-search-results__list')  # here we create a list with jobs\n",
    "            jobs = jobs_lists.find_elements_by_class_name('jobs-search-results__list-item')  # here we select each job to count\n",
    "        # waiting load\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            break\n",
    "            print('isso é tudo')\n",
    "        # the loop below is for the algorithm to click exactly on the number of jobs that is showing in list\n",
    "        # in order to avoid errors that will stop the automation\n",
    "        for n in range(1, len(jobs)+1):\n",
    "            # job click\n",
    "            try: \n",
    "                driver.find_element_by_xpath(f'/html/body/div[5]/div[3]/div[3]/div[2]/div/section[1]/div/div/ul/li[{n}]/div/div/div[1]/div[2]/div[1]/a').click()\n",
    "            # waiting load\n",
    "                time.sleep(1)\n",
    "            # select job description\n",
    "                page = driver.page_source\n",
    "                soup = BeautifulSoup(page,features=\"html.parser\")\n",
    "                job_desc = soup.find('div',{'class': \"jobs-box__html-content jobs-description-content__text t-14 t-normal\"}).find_all('span')\n",
    "                \n",
    "                ul = []\n",
    "                head = []\n",
    "                \n",
    "                for span in job_desc:\n",
    "\n",
    "                    try: data['description'].append(span.text)\n",
    "                    except: data['description'].append('')\n",
    "                        \n",
    "                    try: data['job'].append(jobs[n].text.replace('\\n','|'))\n",
    "                    except: data['job'].append('')\n",
    "                    \n",
    "            except: pass\n",
    "        # click button to change the job list\n",
    "        \n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, f'/html/body/div[5]/div[3]/div[3]/div[2]/div/section[1]/div/div/section/div/ul/li[{i}]/button'))))\n",
    "            time.sleep(5)\n",
    "            driver.find_element_by_xpath( f'/html/body/div[5]/div[3]/div[3]/div[2]/div/section[1]/div/div/section/div/ul/li[{i}]/button').click()\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(\"Last page reached\")\n",
    "            print(i)\n",
    "            break\n",
    "\n",
    "    # Creating a Dataframe with list\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def profile_Search_list(driver,cargo,npages):\n",
    "    \n",
    "    job = '%20'.join(cargo.split())\n",
    "    \n",
    "    driver.get(\n",
    "        f\"https://www.linkedin.com/search/results/people/?geoUrn=%5B%22106057199%22%5D&keywords={job}\")\n",
    "    # waiting load\n",
    "    time.sleep(3)\n",
    "        \n",
    "    links = []\n",
    "    \n",
    "\n",
    "    for i in range(2, npages+1):\n",
    "        try:\n",
    "            page = driver.page_source\n",
    "            soup = BeautifulSoup(page,features=\"html.parser\")\n",
    "            LinkList = soup.find('ul',{'class': \"reusable-search__entity-result-list list-style-none\"})\n",
    "\n",
    "            for link in LinkList.find_all('a'):\n",
    "                links.append(link.attrs['href'])\n",
    "            driver.get(\n",
    "            f\"https://www.linkedin.com/search/results/people/?geoUrn=%5B%22106057199%22%5D&keywords={job}&page={i}\")\n",
    "            # waiting load\n",
    "            time.sleep(3)\n",
    "        \n",
    "        except:\n",
    "            break\n",
    "            print('isso é tudo')\n",
    "\n",
    "    return links\n",
    "\n",
    "def get_profiles(driver,link_list):\n",
    "    \n",
    "    data = {'sobre':[],'experiencia':[],'formação':[]}\n",
    "    \n",
    "    for link in link_list:\n",
    "        driver.get(link)\n",
    "        # waiting load\n",
    "        time.sleep(8)\n",
    "        \n",
    "        try:\n",
    "            page = driver.page_source\n",
    "            soup = BeautifulSoup(page,features=\"html.parser\")\n",
    "            profile = soup.find('div',{'class': \"profile-detail\"})\n",
    "        except: \n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            sobre = profile.find('div',{'class': 'inline-show-more-text inline-show-more-text--is-collapsed mt4 t-14'}).text #sobre\n",
    "            data['sobre'].append(sobre.replace('\\n',' ').replace('  ',' '))\n",
    "        except: \n",
    "            data['sobre'].append('')\n",
    "            \n",
    "        try:\n",
    "            experiencia = profile.find('section',{'id': 'experience-section'}).text\n",
    "            data['experiencia'].append(experiencia.replace('\\n',' ').replace('  ',' '))\n",
    "        except: \n",
    "            data['experiencia'].append('')\n",
    "            \n",
    "        try:\n",
    "            formação = profile.find('section',{'id': 'education-section'}).text\n",
    "            data['formação'].append(formação.replace('\\n',' ').replace('  ',' '))\n",
    "        except: \n",
    "            data['formação'].append('')   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = login(email,senha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Controladoria = job_Search_complete(driver,'Analista de controladoria',local,npages=2)\n",
    "#Contabilidade = job_Search_complete(driver,'Analista de Contabilidade',local,npages=100)\n",
    "#Data_analytics = job_Search_complete(driver,'Analista de dados',local,npages=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.concat([Controladoria,Contabilidade,Data_analytics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel('LinkedIn jobs complete.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linklist = profile_Search_list(driver,'Analista de controladoria',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#resultado = get_profiles(driver,linklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sobre': ['   Analista financeiro com experiência em auditoria (big four), consultoria e contabilidade. Formada em Ciências Contábeis pela Universidade Presbiteriana Mackenzie, cursos de IRFS pela FIPECAFI, inglês avançado e espanhol intermediário. Domínio amplo das funções do Excel, Conhecimento em sistemas SAP e Cognos.Sou comunicativa, gosto de trabalhar em equipe, tenho visão analítica e crítica.Trabalho com entusiasmo e companherismo.      …      visualizar mais      ',\n",
       "  '   Profissional da área de Controladoria, dedicada, responsável e com ampla experiência no setor financeiro.Atuo a 10 anos como Analista Financeira no Banco Bradesco, buscando sempre agregar valor e fazer parte do desenvolvimento da Instituição.Formada em Administração de Empresas pela Universidade Paulista - UNIP e Pós-Graduação em Gestão de Operações de Négocios pela FIA/USP.      …      visualizar mais      '],\n",
       " 'experiencia': ['',\n",
       "  '   Experiência        Nome da empresa Bradesco  Duração total 11 anos 6 meses        Cargo Analista de Controladoria   Período do emprego mar. de 2011 – o momento  Duração 10 anos 9 meses  Localidade Osasco - SP     - Desenvolvimento de relatórios gerenciais e disponibilização de informações para auxílio na tomada de decisão da Diretoria Executiva.- Análise de rentabilidade e monitoramento dos produtos bancários.- Atualização mensal de relatórios com demonstrações e cálculos de índices financeiros.- Atendimento a rede de agências para esclarecimento de dúvidas sobre operações de crédito e alocação de resultados. - Elaboração de planilhas e estudos para gestão de riscos.      …      ver mais             Cargo Estagiária   Período do emprego jun. de 2010 – mar. de 2011  Duração 10 meses        '],\n",
       " 'formação': ['',\n",
       "  '   Formação acadêmica       FIA - Fundação Instituto de Administração Diploma Pós Graduação em Gestão das Operações de Negócios   Período (ou ano previsto para a graduação) 2014 – 2016        Saint Paul Escola de Negócios Diploma Curso Formação de Controller   Período (ou ano previsto para a graduação) 2014 – 2014        Universidade Paulista Diploma Bacharelado em Administração  Área de estudo Administração de Empresas   Período (ou ano previsto para a graduação) 2008 – 2012     ']}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
