{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Skills_Linkedin.xlsx')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6025 entries, 0 to 6024\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  6025 non-null   int64 \n",
      " 1   job         6025 non-null   object\n",
      " 2   skills      6025 non-null   object\n",
      " 3   tipo        6025 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 235.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df['cargo'] == 'Analista de Controladoria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6025"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = df['skills']\n",
    "len(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills.replace(['\\n',\n",
    "                 '^.*?Expect',\n",
    "                 '^.*?Qualifications',\n",
    "                 '^.*?Required',\n",
    "                 '^.*?expected',\n",
    "                 '^.*?Responsibilities',\n",
    "                 '^.*?Requisitos',\n",
    "                 '^.*?Requirements',\n",
    "                 '^.*?Qualificações',\n",
    "                 '^.*?QualificationsRequired1',\n",
    "                 '^.*?você deve ter:',\n",
    "                 '^.*?experiência',\n",
    "                 '^.*?você:',\n",
    "                 '^.*?Desejável',\n",
    "                 '^.*?great',\n",
    "                 '^.*?Looking For',\n",
    "                 '^.*?ll Need',\n",
    "                 '^.*?Conhecimento',\n",
    "                 '^.*?se:',\n",
    "                 '^.*?habilidades',\n",
    "                 '^.*?se:',\n",
    "                 '^.*?REQUISITOS'\n",
    "                 ], '', regex=True)\n",
    "\n",
    "bad_words = ['gender', 'experience', 'application', 'Apply', 'salary', 'todos', 'os', 'company', 'identity', 'sexual', 'orientation',\n",
    "            'de', 'orientação', 'sexual', 'gênero', 'committed', 'toda', 'client', 'conhecimento',\n",
    "            'world', 'year', 'save', 'São', 'Paulo', 'information', 'e', 'orientação', 'sexual', 'equal', 'oppotunity', 'ambiente', 'will',\n",
    "            'Experiência', 'national origin', 'todas', 'work', 'de', 'da', 'years', 'pessoa', 'clients', 'Plano', 'creating',\n",
    "            'employer', 'saúde', 'em', 'working', 'pessoas', 'mais', 'data', 'people', 'dia', 'one', 'knowledges', 'plataforma',\n",
    "            'ou', 'benefício', 'para', 'software', 'opportunity', 'tecnologia', 'você', 'mais', 'solution', 'national', 'origin',\n",
    "            'trabalhar', 'option', 'negócio', 'empresa', 'o', 'sicence', 'team', 'é', 'veteran', 'status', 'etc', 'raça', 'cor', 'belive',\n",
    "            'nossa', 'uma', 'como', 'Scientist', 'ferramenta', 'projeto', 'que', 'job', 'benefícios', 'knowledge', 'toll', 's', 'modelo',\n",
    "            'desconto', 'cultura', 'serviço', 'time', 'se', 'solutions', 'mercado', 'das', 'somos', 'problema', 'mundo', 'race', 'color',\n",
    "            'vaga', 'pelo', 'ser', 'show', 'Seguro', 'Se', 'um', 'Um', 'tool', 'regard', 'without', 'make', 'ao', 'técnica', 'life',\n",
    "            'interested', 'diversidade', 'proud', 'ability', 'sobre', 'options', 'using', 'área', 'nosso', 'na', 'seu', 'product', 'produto',\n",
    "            'building', 'skill', 'model', 'religion', 'Share', 'receive', 'consideration', 'Aqui', 'vida', 'ferramentas', 'Vale', 'Refeição',\n",
    "            'Strong', 'Pay', 'range', 'available', 'part', 'trabalho', 'Alimentação', 'employment', 'qualified', 'applicants', 'gympass',\n",
    "            'está', 'comprometida', 'forma', 'Transporte', 'Yes', 'gente', 'melhor', 'lugar', 'believe', 'moment', 'próximo', 'deasafio',\n",
    "            'dos', 'oportunidade', 'idade', 'new', 'Try', 'Premium', 'deficiência', 'sempre', 'criar', 'employee', 'problemas', 'unavailable',\n",
    "            'Brasil', 'dado', 'hiring', 'trends', 'equipe', 'recent', 'temos', 'build', 'career', 'nós', 'diferencial', 'ma',\n",
    "            'total', 'oferecemos', 'contato', 'tem', 'não', 'free', 'Full','of','to','is','avançado',\n",
    "            'fazer','apuração','apurar','atuação','atuar','realização','realizar','elaoração','elaborar',\n",
    "            'planejamento','planejar','apoio','apoiar','facilidade','revisão','revisar','execução','executar',\n",
    "            'análise','analisar','validação','validar','participação','participar','confecção','confeccionar',\n",
    "            'consolidação','consolidar','desenvolvimento','desenvolver','criação','criar','auxílio','avançado','intermediário'\n",
    "            'auxiliar','acompanhamento','acompanhar','controle','controlar','revisão','revisar','básico','fluente',\n",
    "            'formação','formação','formar','graduação','graduar','superior','cursar','cursando','graduação','graduar',\n",
    "            'vivencia','vivência','atuar','atuação','experiencia','experiência','conhecimento','conhecer','habilidade',\n",
    "            'capacidade','entendimento','entender','facilidade','avançado','intermediário','intermediario','basico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words\n",
    "stopw = 'de a o que e do da em um para é com não uma os no se na por mais as dos como mas foi ao ele das tem à seu sua ou ser quando muito há nos já está eu também só pelo pela até isso ela entre era depois sem mesmo aos ter seus quem nas me esse eles estão você tinha foram essa num nem suas meu às minha têm numa pelos elas havia seja qual será nós tenho lhe deles essas esses pelas este fosse dele tu te vocês vos lhes meus minhas teu tua teus tuas nosso nossa nossos nossas dela delas esta estes estas aquele aquela aqueles aquelas isto aquilo estou está estamos estão estive esteve estivemos estiveram estava estávamos estavam estivera estivéramos esteja estejamos estejam estivesse estivéssemos estivessem estiver estivermos estiverem hei há havemos hão houve houvemos houveram houvera houvéramos haja hajamos hajam houvesse houvéssemos houvessem houver houvermos houverem houverei houverá houveremos houverão houveria houveríamos houveriam sou somos são era éramos eram fui foi fomos foram fora fôramos seja sejamos sejam fosse fôssemos fossem for formos forem serei será seremos serão seria seríamos seriam tenho tem temos tém tinha tínhamos tinham tive teve tivemos tiveram tivera tivéramos tenha tenhamos tenham tivesse tivéssemos tivessem tiver tivermos tiverem terei terá teremos terão teria teríamos teriam'.split()\n",
    "\n",
    "stopw = [*stopw,*bad_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    WNLTokens = []\n",
    "    chars = []\n",
    "    \n",
    "    WNLemmatizer = WordNetLemmatizer()\n",
    "    for ch in text:\n",
    "        if ch not in string.punctuation:\n",
    "            chars.append(ch)\n",
    "        else:\n",
    "            chars.append(' ')\n",
    "    txt = ''.join(chars)        \n",
    "        \n",
    "    tokens = word_tokenize(txt)\n",
    "    for t in tokens:\n",
    "        WNLTokens.append(WNLemmatizer.lemmatize(t))\n",
    "    \n",
    "    return WNLTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.9,min_df=3,stop_words=stopw,tokenizer=tokenize,ngram_range=(1, 2))\n",
    "dtmtfidf = tfidf.fit_transform(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=1, random_state=42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "LDA = LatentDirichletAllocation(n_components=1,random_state=42)\n",
    "LDA.fit(dtmtfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 for topic 0\n",
      "['atividades', 'conhecimentos', 'projetos', 'indicadores', 'completo', 'pacote office', 'ciências contábeis', 'áreas', 'ciências', 'sap', 'processos', 'tableau', 'contabilidade', 'resultados', 'pacote', 'contábil', 'sistema', 'inglês', 'power bi', 'elaboração', 'bi', 'relatórios', 'contábeis', 'análises', 'python', 'power', 'parte', 'office', 'excel', 'sql']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 20 for topic {i}')\n",
    "    print([tfidf.get_feature_names()[c] for c in topic.argsort()[-30:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
